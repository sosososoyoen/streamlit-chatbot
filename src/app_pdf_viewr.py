import re, base64
import streamlit as st
import streamlit.components.v1 as components
from streamlit_pdf_viewer import pdf_viewer

# ==============================================
# 1) PDF ë¦¬íŠ¸ë¦¬ë²„Â·ì²´ì¸ ìºì‹œ (í•œë²ˆë§Œ ìƒì„±)
# ==============================================
@st.experimental_singleton
def get_chain_and_retriever(pdf_bytes):
    # (ì˜ˆì‹œ) PyPDFLoader â†’ split â†’ ë²¡í„°ìŠ¤í† ì–´ â†’ retriever â†’ PromptTemplate â†’ LLMChain
    from langchain.document_loaders import PyPDFLoader
    from langchain.text_splitter     import RecursiveCharacterTextSplitter
    from langchain.embeddings         import OpenAIEmbeddings
    from langchain.vectorstores       import Chroma
    from langchain import PromptTemplate, LLMChain, OpenAI

    loader = PyPDFLoader(pdf_bytes)
    docs   = loader.load()
    chunks = RecursiveCharacterTextSplitter(1000).split_documents(docs)
    store  = Chroma.from_documents(chunks, OpenAIEmbeddings(api_key=st.secrets["OPENAI_KEY"]))
    retr   = store.as_retriever(search_kwargs={"k":3})
    prompt = PromptTemplate(
        template="""
ë¬¸ë§¥(Context) ì•ˆì˜ [p.X] íƒœê·¸ë¥¼ ì°¸ê³ í•´ì„œ ë‹µë³€í•  ë•Œ ë°˜ë“œì‹œ ì¶œì²˜ë¥¼ ë‹¬ì•„ì¤˜.

ë¬¸ë§¥:
{context}

ì§ˆë¬¸:
{question}
""",
        input_variables=["context","question"]
    )
    llm   = OpenAI(model="gpt-4o-mini", temperature=0, api_key=st.secrets["OPENAI_KEY"])
    chain = LLMChain(llm=llm, prompt=prompt)
    return chain, retr

# ==============================================
# 2) ì„¸ì…˜ ìŠ¤í…Œì´íŠ¸ ì´ˆê¸°í™” (í•œë²ˆë§Œ)
#    â€” structure-vision íŒ¨í„´ ì°¸ê³  :contentReference[oaicite:0]{index=0}
# ==============================================
if 'pdf_ref'     not in st.session_state: st.session_state['pdf_ref'] = None
if 'scroll_page' not in st.session_state: st.session_state['scroll_page'] = 1

# ==============================================
# 3) íŒŒì¼ ì—…ë¡œë“œ (key ê³ ì •)
# ==============================================
uploaded = st.file_uploader("PDF íŒŒì¼ ì„ íƒ", type="pdf", key="pdf_uploader")
if uploaded is not None:
    # ìƒˆ íŒŒì¼ì´ë©´ ì„¸ì…˜ì— ì €ì¥
    if st.session_state['pdf_ref'] is None or st.session_state['pdf_ref'].name != uploaded.name:
        st.session_state['pdf_ref'] = uploaded
        st.session_state['scroll_page'] = 1

pdf_ref = st.session_state['pdf_ref']
pdf_bytes = pdf_ref.getvalue() if pdf_ref else None

# ==============================================
# 4) ë ˆì´ì•„ì›ƒ: ì¢Œìš° ì»¬ëŸ¼
# ==============================================
col1, col2 = st.columns([1,1])
with col2:
    st.header("ğŸ‘€ PDF ë·°ì–´")
    if pdf_bytes:
        # pdf-viewer ì»´í¬ë„ŒíŠ¸ì— scroll_to_page ì „ë‹¬
        pdf_viewer(input=pdf_bytes, width="100%", height=800,
                   scroll_to_page=st.session_state['scroll_page'])
    else:
        st.info("ì™¼ìª½ì—ì„œ PDFë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")

with col1:
    st.header("ğŸ’¬ ì§ˆë¬¸ & ë‹µë³€")
    question = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”")
    if st.button("ì§ˆë¬¸í•˜ê¸°") and pdf_bytes:
        # 5) ìºì‹œëœ ì²´ì¸Â·ë¦¬íŠ¸ë¦¬ë²„ ì–»ê¸°
        chain, retriever = get_chain_and_retriever(pdf_bytes)

        # 6) ë¬¸ë§¥ ìƒì„±
        docs    = retriever.get_relevant_documents(question)
        context = "\n\n".join(
            f"[p.{d.metadata.get('page','?')}] {d.page_content[:200]}â€¦"
            for d in docs
        )

        # 7) ì²´ì¸ ì‹¤í–‰
        response = chain.run({"context": context, "question": question})
        st.markdown(response)

        # 8) ë‹µë³€ì—ì„œ ì‹¤ì œ ì“´ [p.X] íƒœê·¸ë§Œ íŒŒì‹±í•´ì„œ ë²„íŠ¼ìœ¼ë¡œ
        pages = sorted({int(p) for p in re.findall(r'\[p\.(\d+)\]', response)})
        if pages:
            st.markdown("**ğŸ“‘ ì¶œì²˜ í˜ì´ì§€:**")
            btn_cols = st.columns(len(pages))
            for col, pg in zip(btn_cols, pages):
                if col.button(f"p.{pg}", key=f"btn_{pg}"):
                    st.session_state['scroll_page'] = pg
