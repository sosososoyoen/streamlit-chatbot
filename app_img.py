import base64
from io import BytesIO

import streamlit as st
from PIL import Image
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_openai import ChatOpenAI

with st.sidebar:
    openai_api_key = st.text_input("OpenAI API Key", key="chatbot_api_key", type="password")
    "[Get an OpenAI API key](https://platform.openai.com/account/api-keys)"
    "[View the source code](https://github.com/sosososoyoen/streamlit-chatbot)"

st.title("ğŸ‘—Langchain + OpenAI + Image")
st.caption("ğŸš€ ì—…ë¡œë“œí•œ ì´ë¯¸ì§€ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ì´ ìƒì„±ë©ë‹ˆë‹¤.")

if "image_data_list" not in st.session_state:
    st.session_state.image_data_list = []

if images := st.file_uploader("ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.", type=['png', 'jpg', 'jpeg'], accept_multiple_files=True):

    for image in images:
        img = Image.open(image)
        if img.format.lower() not in ['png', 'jpeg', 'jpg']:
            st.error("ì§€ì›ë˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ í˜•ì‹ì…ë‹ˆë‹¤. ì§€ì›ë˜ëŠ” í˜•ì‹: png, jpg, jpeg")
        else:
            st.image(img)

            # ì´ë¯¸ì§€ë¥¼ ë©”ëª¨ë¦¬ ë²„í¼ì— ì €ì¥ í›„ Base64 ì¸ì½”ë”©
            buffered = BytesIO()
            img.save(buffered, format=img.format)
            image_base64 = base64.b64encode(buffered.getvalue()).decode("utf-8")
            st.session_state.image_data_list.append({"format": img.format.lower(), "base64": image_base64})

if "messages" not in st.session_state:
    st.session_state.messages = [
        SystemMessage(content="ë‹¹ì‹ ì€ íŒ¨ì…˜ ìŠ¤íƒ€ì¼ ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì˜¬ë¼ì˜¨ ì‚¬ì§„ì„ ë³´ê³  ê·¸ ì‚¬ëŒì—ê²Œ ì–´ìš¸ë¦¬ëŠ” ìŠ¤íƒ€ì¼ì„ ì¶”ì²œí•´ì£¼ì„¸ìš”.")
    ]

for message in st.session_state.messages:
    if isinstance(message, SystemMessage):
        continue
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if prompt := st.chat_input("ì–´ë–¤ íŒ¨ì…˜ ìŠ¤íƒ€ì¼ì„ ì¶”ì²œë°›ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?"):
    if not openai_api_key:
        st.info("Please add your OpenAI API key to continue.")
        st.stop()
    model = ChatOpenAI(model="gpt-4o-mini", api_key=st.secrets["OPENAI_KEY"])
    with st.chat_message("user"):
        st.markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    msgs = []
    img_msgs = [{"role": "user", "content": []}]

    for msg in st.session_state.messages:
        if isinstance(msg, SystemMessage):
            msgs.append(msg)
        elif msg["role"] == "user":
            msgs.append(HumanMessage(
                content=msg["content"],
            ))
        else:
            msgs.append(AIMessage(
                content=msg["content"],
            ))

    for image_data in st.session_state.image_data_list:
        img_msgs[0]["content"].append({
            "type": "image_url",
            "image_url": {"url": f"data:image/{image_data['format']};base64,{image_data['base64']}"}
        })

    with st.chat_message("assistant"):
        result = model.invoke(msgs + img_msgs)
        st.session_state.messages.append({"role": "assistant", "content": result.content})
        response = result.content
        st.markdown(response)
