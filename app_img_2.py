import base64
import uuid
from io import BytesIO

import streamlit as st
from PIL import Image, UnidentifiedImageError
from langchain_core.chat_history import InMemoryChatMessageHistory
from langchain_openai import ChatOpenAI
from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph import StateGraph, START, MessagesState
from langchain_core.messages import SystemMessage, HumanMessage

# â”€â”€ 1) ì„¸ì…˜ë³„ íˆìŠ¤í† ë¦¬ ê´€ë¦¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if "session_id" not in st.session_state:
    st.session_state.session_id = str(uuid.uuid4())

if "chats" not in st.session_state:
    st.session_state.chats = {}
if "image_data_list" not in st.session_state:
    st.session_state.image_data_list = []


def get_chat_history(sid: str) -> InMemoryChatMessageHistory:
    if sid not in st.session_state.chats:
        st.session_state.chats[sid] = InMemoryChatMessageHistory()
    return st.session_state.chats[sid]


session_id = st.session_state.session_id
history = get_chat_history(session_id)

# â”€â”€ 2) LangGraph ê·¸ë˜í”„ ì •ì˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

workflow = StateGraph(state_schema=MessagesState)
model = ChatOpenAI(model="gpt-4o-mini", api_key=st.secrets["OPENAI_KEY"])

SYSTEM_PROMPT = SystemMessage(
    content=(
        "ë‹¹ì‹ ì€ íŒ¨ì…˜ ìŠ¤íƒ€ì¼ ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. "
        "ì˜¬ë¼ì˜¨ ì „ì‹  ì‚¬ì§„ì„ ë³´ê³  ê·¸ ì‚¬ëŒì—ê²Œ ì–´ìš¸ë¦¬ëŠ” ìŠ¤íƒ€ì¼ì„ ì¶”ì²œí•´ì£¼ì„¸ìš”."
    )
)



def call_model(state: MessagesState) -> dict:
    user_msg = state["messages"][0]
    print("ìœ ì €ë©”ì„¸ì§€",prompt_template)
    all_msgs = history.messages + state["messages"]
    res = model.invoke(all_msgs)
    history.add_message(state["messages"] + [res])
    return {"messages": res}


workflow.add_edge(START, "model")
workflow.add_node("model", call_model)
memory = MemorySaver()
app = workflow.compile(checkpointer=memory)

# â”€â”€ 3) Streamlit UI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.title('ğŸ‘— íŒ¨ì…˜ ì¶”ì²œ ë´‡')

uploaded_file = st.file_uploader(
    "ë³¸ì¸ì˜ ì „ì‹ ì´ ë³´ì´ëŠ” ì‚¬ì§„ì„ ì˜¬ë ¤ì£¼ì„¸ìš”!",
    type=["png", "jpg", "jpeg", "webp"],
    accept_multiple_files=True
)
if uploaded_file:
    st.session_state.image_data_list.clear()
    cols = st.columns(len(uploaded_file))
    for col, file in zip(cols, uploaded_file):
        try:
            img = Image.open(file)
        except UnidentifiedImageError:
            st.error(f"{file.name} ì€(ëŠ”) ì§€ì›ë˜ì§€ ì•ŠëŠ” í˜•ì‹ì…ë‹ˆë‹¤.")
            continue
        col.image(img, use_container_width=True)
        buf = BytesIO()
        img.save(buf, format=img.format)
        b64 = base64.b64encode(buf.getvalue()).decode("utf-8")
        st.session_state.image_data_list.append({
            "format": img.format.lower(),
            "base64": b64
        })

for msg in history.messages:
    role = "user" if isinstance(msg, HumanMessage) else "assistant"
    with st.chat_message(role):
        content = msg
        print(content)
        # if isinstance(content, list):
        #     for item in content:
        #         if item.get("type") == "text":
        #             st.markdown(item["text"])
        #         elif item.get("type") == "image_url":
        #             st.image(item["image_url"]["url"])
        # else:
        #     st.markdown(content)

config = {"configurable": {"thread_id": session_id}}


def handle_submit():
    user_input = st.session_state.user_input
    st.chat_message("user").write(user_input)
    # multimodal = [
    #     {
    #         "type": "text",
    #         "text": (
    #             "ë‹¤ìŒì€ ì‚¬ìš©ìê°€ ì˜¬ë¦° ì „ì‹  ì‚¬ì§„ì…ë‹ˆë‹¤. "
    #             "ì´ ì‚¬ëŒì˜ ì²´í˜•ê³¼ ì–´ìš¸ë¦¬ëŠ” íŒ¨ì…˜ ìŠ¤íƒ€ì¼ì„ ì¶”ì²œí•´ì£¼ì„¸ìš”."
    #         )
    #     }
    # ]
    # for img in st.session_state.image_data_list:
    #     multimodal.append({
    #         "type": "image_url",
    #         "image_url": {
    #             "url": f"data:image/{img['format']};base64,{img['base64']}"
    #         }
    #     })
    # multimodal.append({"type": "text", "text": user_input})
    user_msg = HumanMessage(user_input)
    output = app.invoke({"messages": [user_msg]}, config)
    contents = [msg.content for msg in output["messages"]]
    st.chat_message("assistant").write(contents[-1])


st.chat_input(
    placeholder="ì§ˆë¬¸ì„ ì…ë ¥í•˜ê³  Enterë¥¼ ëˆŒëŸ¬ì£¼ì„¸ìš”â€¦",
    key="user_input",
    on_submit=handle_submit,
)
