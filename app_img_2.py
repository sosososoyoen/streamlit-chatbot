import base64
import uuid
from io import BytesIO

import streamlit as st
from PIL import Image, UnidentifiedImageError
from langchain_core.chat_history import InMemoryChatMessageHistory
from langchain_openai import ChatOpenAI
from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph import StateGraph, START, MessagesState
from langchain_core.messages import SystemMessage, HumanMessage, BaseMessage
from typing import Annotated
from typing_extensions import TypedDict
from langchain_core.runnables import RunnableConfig
from langgraph.graph.message import add_messages

st.title('ğŸ‘— íŒ¨ì…˜ ì¶”ì²œ ë´‡')

if "session_id" not in st.session_state:
    st.session_state.session_id = str(uuid.uuid4())

if "chats" not in st.session_state:
    st.session_state.chats = {}
if "image_data_list" not in st.session_state:
    st.session_state.image_data_list = []
config = {"configurable": {"session_id": st.session_state.session_id}}


def get_chat_history(sid: str) -> InMemoryChatMessageHistory:
    chats = st.session_state.chats
    if sid not in chats:
        chats[sid] = InMemoryChatMessageHistory()
    return chats[sid]


session_id = st.session_state.session_id

builder = StateGraph(state_schema=MessagesState)
model = ChatOpenAI(model="gpt-4o-mini", api_key=st.secrets["OPENAI_KEY"])

SYSTEM_PROMPT = SystemMessage(
    content=(
        "ë‹¹ì‹ ì€ íŒ¨ì…˜ ìŠ¤íƒ€ì¼ ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. "
        "ì˜¬ë¼ì˜¨ ì „ì‹  ì‚¬ì§„ì„ ë³´ê³  ê·¸ ì‚¬ëŒì—ê²Œ ì–´ìš¸ë¦¬ëŠ” ìŠ¤íƒ€ì¼ì„ ì¶”ì²œí•´ì£¼ì„¸ìš”."
    )
)


def call_model(state: MessagesState, config: RunnableConfig) -> list[BaseMessage]:
    chat_history = get_chat_history(config["configurable"]["session_id"])
    messages = list(chat_history.messages) + state["messages"]
    ai_message = model.invoke(messages)
    chat_history.add_messages(state["messages"] + [ai_message])
    return {"messages": ai_message}


builder.add_edge(START, "model")
builder.add_node("model", call_model)
graph = builder.compile()

if images := st.file_uploader("ë³¸ì¸ì˜ ì „ì‹ ì´ ë³´ì´ëŠ” ì‚¬ì§„ì„ ì˜¬ë ¤ì£¼ì„¸ìš”!", type=['png', 'jpg', 'jpeg', 'webp'],
                              accept_multiple_files=True):
    # íŒŒì¼ í™•ì¥ìì™€ ì‹¤ì œ ì´ë¯¸ì§€ í˜•ì‹ ê²€ì¦
    for image in images:
        img = Image.open(image)
        if img.format.lower() not in ['png', 'jpeg', 'jpg', 'webp']:
            st.error("ì§€ì›ë˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ í˜•ì‹ì…ë‹ˆë‹¤. ì§€ì›ë˜ëŠ” í˜•ì‹: png, jpg, jpeg")
        else:
            st.image(img)

            # ì´ë¯¸ì§€ë¥¼ ë©”ëª¨ë¦¬ ë²„í¼ì— ì €ì¥ í›„ Base64 ì¸ì½”ë”©
            buffered = BytesIO()
            img.save(buffered, format=img.format)
            image_base64 = base64.b64encode(buffered.getvalue()).decode("utf-8")
            st.session_state.image_data_list.append({"format": img.format.lower(), "base64": image_base64})

# ì±— ë‚´ì—­ ë Œë”ë§
if "chats" in st.session_state:
    chat_history = get_chat_history(st.session_state.session_id)
    for msg in chat_history.messages:
        role = "user" if isinstance(msg, HumanMessage) else "assistant"
        with st.chat_message(role):
            st.markdown(msg.content)


def handle_submit():
    user_input = st.session_state.user_input
    if not user_input:
        return

    chat_history = get_chat_history(st.session_state.session_id)

    messages = [{"role": "user", "type": "text", "content": user_input}]

    for image_data in st.session_state.image_data_list:
        messages.append({
            "role": "user",
            "type": "image_url",
            "image_url": {"url": f"data:image/{image_data['format']};base64,{image_data['base64']}"}
        })

    res = graph.invoke({"messages": messages}, config)
    res["messages"][-1].pretty_print()


st.chat_input(
    placeholder="ì§ˆë¬¸ì„ ì…ë ¥í•˜ê³  Enterë¥¼ ëˆŒëŸ¬ì£¼ì„¸ìš”â€¦",
    key="user_input",
    on_submit=handle_submit,
)
